============================
Summary of Method GONet
============================

GANs
--------------
Consist of:
- Generator (Gen)
	Captures distribution of training data and can produce examples
	from training data's manifold from a latent input variable 'z'.
	Latent variable 'z' is sampled from some distribution (eg. Gaussian)

- Discriminator (Dis)
	Tries to distinguish samples generated by Gen from actual samples
	in the dataset.

GANs are unsupervised, use unlabelled data to learn both Gen and Dis,
simultaneously.

Basic Idea:
Set up a game between two players (Gen and Dis). Gen creates samples
intended to come from same distribution as training data. Dis examines
samples to determine whether they are real or fake. Gen tries to fool Dis.

Each model has it's own cost function Gen: Jg(G,D), Dis: Jd(D,G).


Training GANs:
----------------
Two scenarios
1) A data point x (image) is sampled from the dataset and fed into Dis.
	Dis tries to assign high probability to this datapoint (D(x) = 1)

2) An input z is randomly sampled from the prior over the latent variables (some distribution).
	This input is fed into Gen to get x_fake = G(z).
	Dis recieves this fake input and tries to assign it a low probability D(G(z)) = 0.
	Gen tries to maximise the probability D(G(z)) by fooling Dis.

Approximately 50 % of the time, Dis should be given real datapoints and
the other 50 % should be fake (made by Gen)
If both models have sufficient capacity, then the Nash equilibrium corresponds to
G(z) being drawn from the true distribution of the training data; hence,
the discriminator can't do better than a random guess (average of D(x) = 1/2)

Training Procedure:
	At each step two minibatches are sampled:
		- One from the dataset (a batch of x's)
		- One from the latent dist. (a batch of z's)
	These are fed through Gen and Dis according to scenarios 1) and 2) above
	The losses are calculated using specially designed loss functions
	Two gradient steps are made simultaneously (one for Dis, one for Gen)


Deep Convolutional GANs (DCGANs)
-----------------------------------
Gen outputs an image I' = Gen(z) that looks like the training data.


=================================================================================================
GONet
================================================================================================
Takes an input image from the robot's camera as it is driving along.
Generates a fake image I' that looks like a traversable version of I.
If the current scene is in fact traversable, I and I' should be very similar.
The network then classifies the scene as traversable or not based on this similarity. 

-----------------------------------------------------
>> Feature Extraction Module (Auxiliary Autoencoder)
-----------------------------------------------------
1) First generate an image I' = Gen(z) that is similar to an input image I and looks
   like it came from the manifold of positive examples.
   (ie. I' is a traversable version of I)

2) Compare the generated image I' to the original image.
	> Apply 3 metrics
	1. The residual difference between the images        |I - I'|
	2. The difference between the discriminator features |f(I) - f(I')|
	3. The discriminator features of the input image     f(I)

	Discriminator features f are the last conv layer of the Dis network.


Need to select z so that I' = Gen(z) looks like I.
   Use another network to output z given input image I (eg. z = InvGen(I)).
   InvGen is the same as Gen but in reverse order.
   It takes in an image I and outputs a vector z (of size 100)

   Feature Extraction Module consists of InvGen followed by Gen. (I' = Gen(InvGen(I)))


-------------------------
>> Classification Module
-------------------------
1) Processes each of the features independently using fully connected
   layers. Outputs a SCALAR for each.
   >>>>>!!!IDEA: Use conv layers to process the features instead!!!<<<<<<<<<<<<<<<<<<<<<<

2) The 3 Scalars are concatenated into a 3x1 vector and passed to another
   FC layer with Sigmoid activation

3) Output is the traversibility probability. Optimize the Classification Module using MSE.
	>>>>>!!!IDEA: Consider cross-entropy loss !!!<<<<<<<<<<<<<<<<<<<<<<<<



--------------------------
>> Training GONet
--------------------------
3 step process:
================
1) Train DCGAN Dis and Gen
	> Use all automatically labelled POSITIVE examples.
	> Generate Z vectors (of size 100) from std normal distribution
	> Pass Z vector batches through Gen then Dis (labels should be all 0.0)
	> Pass data batches directly through Dis (labels should be all 1.0)
	> Dis loss use Binary cross-entropy (two minibatches are used, one from data, one from Gen)
		min Ld = -log(D(x)) - log(1 - G(z))
	> Gen loss use min Lg = -log(D(G(z)))

2) Train the AutoEncoder
	> Freeze the weights of Gen
	> Use all automatically labelled POSITIVE examples
	> Loss function given in paper

3) Train Classifier
	> Use hand labelled POSITIVE and NEGATIVE examples.
	> Use 400 positive and 400 negative examples
	> Use MSE for loss
	> Use early stopping to prevent overfitting


------------------------
>> Data
------------------------
Multiple Datasets: GS1, GS2.
GS2 is stereo (we can ignore for now)

All images need to be resized to 3x128x128

Augmentation:
	Flip the images in GS1 horizontally



Training the DCGAN - tricks:
-----------------------------
To encourage the discriminator to estimate soft probabilities rather than to
extrapolate to extremely confident classification, we can use a technique called
one-sided label smoothing.
We can write this in TensorFlow code as:

	> d_on_data = discriminator_logits(data_minibatch)
	> d_on_samples = discriminator_logits(samples_minibatch)
	> loss = tf.nn.sigmoid_crossentropy_withlogits(d_on_data, 1.) + tf.nn.sigmoid_crossentropy_withlogits(d_on_samples, 0.)

The idea of one-sided label smoothing is to replace the target for the real
examples with a value slightly less than one, such as .9:

	> loss = tf.nn.sigmoid_crossentropy_withlogits(d_on_data, .9) + tf.nn.sigmoid_crossentropy_withlogits(d_on_samples, 0.)

This prevents extreme extrapolation behavior in the discriminator


- Normalize inputs to the range [-1, 1] and use tanh in the generator output.
- Flip the labels and loss function when training the generator.
- Sample Gaussian random numbers as input to the generator.
- Use mini batches of all real or all fake for calculating batch norm statistics.
- Use Leaky ReLU in the generator and discriminator.
- Use Average pooling and stride for downsampling; use ConvTranspose2D and stride for upsampling.
- Use label smoothing in the discriminator, with small random noise.
- Add random noise to the labels in the discriminator.
- Use DCGAN architecture, unless you have a good reason not to.
- A loss of 0.0 in the discriminator is a failure mode.
- If loss of the generator steadily decreases, it is likely fooling the discriminator with garbage images.
- Use labels if you have them.
- Add noise to inputs to the discriminator and decay the noise over time.
- Use dropout of 50 percent during train and generation.

- Use different learning rates for Gen and Dis  (try .0004 for the discriminator and 0.0001 for the generator)
- Try different input noise vector (z) sizes e.g. 100, 128, 256
- Use small batch sizes (8, 16, 32, 64)
- Spectral normalization
- Try Wasserstein loss Ld = D(x) - D(G(z)), Lg = -D(G(z))
- Set beta1 for Adam = 0.5